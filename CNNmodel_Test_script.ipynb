{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNNmodel_Test_script.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kNLvSwkeu7Z",
        "outputId": "3a3fc6b7-c543-49cf-be01-7f7fae62259b"
      },
      "source": [
        "!pip install simplejson\n",
        "!pip install pickle5\n",
        "!pip install nltk\n",
        "import pickle5 as pickle\n",
        "import nltk\n",
        "import string\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import simplejson\n",
        "import json\n",
        "#CNN Imports\n",
        "import os\n",
        "import sys\n",
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import model_from_json\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: simplejson in /usr/local/lib/python3.7/dist-packages (3.17.5)\n",
            "Requirement already satisfied: pickle5 in /usr/local/lib/python3.7/dist-packages (0.0.11)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qD97kYMEe4QV",
        "outputId": "7ce5b8ce-da58-4fb0-d3bc-66292cef8af2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukFpNX8WfClo"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "prefix = \"/content/gdrive/My Drive/NLP Assignments/\"\n",
        "sys.path.append(prefix)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgZbXOxxfDcV"
      },
      "source": [
        "json_filename = prefix+\"bestmodel.json\"\n",
        "json_file = open(json_filename, \"r\")\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWC6EZzQf3TL",
        "outputId": "0ca391f0-ee92-4df5-ef29-4268b7aba186"
      },
      "source": [
        "model_filename = prefix+\"bestmodel.h5\"\n",
        "loaded_model.load_weights(model_filename)\n",
        "print(\"Loaded model from disk\")"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded model from disk\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPL_mTCXe4Wj"
      },
      "source": [
        "test_filename = prefix+\"Test.csv\"\n",
        "test_reviews =pd.read_csv(test_filename)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1qqMoZue4Zi",
        "outputId": "a195f752-cbe7-4942-9631-33647b7fb3ee"
      },
      "source": [
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "ps = nltk.PorterStemmer()\n",
        "MAX_WORDS = 2500\n",
        "MAX_SEQUENCE_LENGTH = 734\n",
        "\n",
        "def clean_text(text):\n",
        "    text = \"\".join([word.lower() for word in text if word not in string.punctuation])\n",
        "    tokens = re.split('\\W+', text)\n",
        "    text = [ps.stem(word) for word in tokens if word not in stopwords]\n",
        "    return text\n",
        "\n",
        "test_reviews['clean_text2'] = test_reviews['text'].apply(lambda x: clean_text(x))\n",
        "X_test, y_test = test_reviews['clean_text2'], test_reviews['label']\n",
        "\n",
        "# loading tokenizer\n",
        "token_filename = prefix+\"tokenizer.pickle\"\n",
        "with open(token_filename, 'rb') as handle:\n",
        "    tokenizer = pickle.load(handle)\n",
        "\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "X_test_data = pad_sequences(X_test_seq, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "labels_test = to_categorical(np.asarray(y_test))\n",
        "print('Shape of testing data tensor:', X_test_data.shape)\n",
        "print('Shape of testing label tensor:', labels_test.shape)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of testing data tensor: (5000, 734)\n",
            "Shape of testing label tensor: (5000, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBRw_smOiy4T",
        "outputId": "1d90c29c-8b71-46f1-e1e0-bff808d6f7cc"
      },
      "source": [
        "loaded_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "score = loaded_model.evaluate(X_test_data, y_test, verbose=0)\n",
        "print (\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 87.68%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_5Ey2mPizBI",
        "outputId": "f2bbf8c7-4a44-4119-e212-bbf417618c45"
      },
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "\n",
        "# compile the model\n",
        "loaded_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc',f1_m,precision_m, recall_m])\n",
        "loss_test, accuracy_test, f1_score_test, precision_test, recall_test = loaded_model.evaluate(X_test_data, y_test, verbose=0)\n",
        "print('F1 score for test dataset :',f1_score_test*100)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score for test dataset : 87.78820633888245\n"
          ]
        }
      ]
    }
  ]
}